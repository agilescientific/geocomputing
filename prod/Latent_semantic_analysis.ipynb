{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNSUPERVISED LEARNING\n",
    "\n",
    "# Recommending documents with LSA\n",
    "\n",
    "----\n",
    "\n",
    "#### ❗ NLTK is hard to install. I recommend running this notebook in Google Colab instead: https://drive.google.com/file/d/1xel4VmTqzFoZkOiEijyGhYuH6BQW5lYM/view?usp=sharing\n",
    "\n",
    "----\n",
    "\n",
    "We'd like to find documents with similar content to a document we like, but without having to rely on tagging or other labels. This is what **latent semantic analysis** is for. We can 'sense' the meaning of a document from the words it contains.\n",
    "\n",
    "Inspired by and/or based on [**science concierge**](https://github.com/titipata/science_concierge) and [**Chris Clark's repo**](https://github.com/groveco/content-engine) on content-based recommendation.\n",
    "\n",
    "[This blog post](https://www.themarketingtechnologist.co/a-recommendation-system-for-blogs-content-based-similarity-part-2/) is also really good. [Pysuggest](https://pypi.python.org/pypi/pysuggest) might be worth looking at, and so might [Crab](https://muricoca.github.io/crab/).\n",
    "\n",
    "Believe it or not, we can do all of it in about 10 lines of code!\n",
    "\n",
    "----\n",
    "\n",
    "We'll start with some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uranium Measurement By Airborne Gamma‐Ray Spec...</td>\n",
       "      <td>In the airborne measurement of uranium, window...</td>\n",
       "      <td>10.1190/1.1440542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coupling In Amplitude Variation With Offset An...</td>\n",
       "      <td>Linear amplitude-variation-with-offset (AVO) a...</td>\n",
       "      <td>10.1190/geo2012-0429.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Principal Component Spectral Analysis</td>\n",
       "      <td>Spectral decomposition methods help illuminate...</td>\n",
       "      <td>10.1190/1.3119264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extended Arrays For Marine Seismic Acquisition</td>\n",
       "      <td>In‐line arrays for both source and receiver ha...</td>\n",
       "      <td>10.1190/1.1440827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Modeling Anisotropic Static Elastic Properties...</td>\n",
       "      <td>We have quantified the effects of clay fractio...</td>\n",
       "      <td>10.1190/geo2015-0575.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Uranium Measurement By Airborne Gamma‐Ray Spec...   \n",
       "1  Coupling In Amplitude Variation With Offset An...   \n",
       "2              Principal Component Spectral Analysis   \n",
       "3     Extended Arrays For Marine Seismic Acquisition   \n",
       "4  Modeling Anisotropic Static Elastic Properties...   \n",
       "\n",
       "                                            abstract                     doi  \n",
       "0  In the airborne measurement of uranium, window...       10.1190/1.1440542  \n",
       "1  Linear amplitude-variation-with-offset (AVO) a...  10.1190/geo2012-0429.1  \n",
       "2  Spectral decomposition methods help illuminate...       10.1190/1.3119264  \n",
       "3  In‐line arrays for both source and receiver ha...       10.1190/1.1440827  \n",
       "4  We have quantified the effects of clay fractio...  10.1190/geo2015-0575.1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/seg/2017-tle-hall/master/data/title_abstract_doi.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the stemmer and tokenizer.\n",
    "stemmer, tokenizer = PorterStemmer(), RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Make a function to preprocess each item in the data.\n",
    "def preprocess(item):  # 3\n",
    "    return ' '.join(stemmer.stem(token) for token in tokenizer.tokenize(item))\n",
    "\n",
    "# Apply the preprocessing.\n",
    "data = [preprocess(item) for item in df.abstract]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the document matrix\n",
    "\n",
    "The matrix is a **term frequency, inverse document frequency** or \"tfidf\" matrix. This counts how many times words and/or phrases ('terms') appear in a document, then scales those frequencies to the inverse of how frequent they are in the cohort. So a rare word like 'coulomb' carries more weight than a common one like 'seismic'.\n",
    "\n",
    "The `sklearn` implementation automatically filters 'stop' words, eliminating things like 'the' or 'this'. It works just like `sklearn`'s other models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "vecs = tfidf.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting matrix has one row for each document, and one column for each 'term'. If we include n-grams, which are groups of words, the matrix will be very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6133)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the number of dimensions\n",
    "\n",
    "To make the matrix more manageable, we can reduce the number of dimensions with singular value decomposition. We'll reduce it down to 100 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100).fit_transform(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and store the distance tree\n",
    "\n",
    "The distance tree is a fast dta structure for finding nearest neighbours in a high-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "tree = KDTree(svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the tree for recommendations\n",
    "\n",
    "Now we can find a paper we're interested in and try to find similar papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Terracing Operator For Physical Property Mapping With Potential Field Data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 333\n",
    "\n",
    "df.title[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U.S. National Magnetic Anomaly Survey Specifications Workshop Report',\n",
       " 'High-Resolution Gravity Study Of The Gray Fossil Site',\n",
       " 'Geologic Implications Of Aeromagnetic Data For The Eastern Continental Margin Of The United States',\n",
       " 'Calculation Of Magnitude Magnetic Transforms With High Centricity And Low Dependence On The Magnetization Vector Direction',\n",
       " 'The World‐Wide Gravity Program Of The Mapping And Charting Research Laboratory Of Ohio State University']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommend 5 docs for a single document.\n",
    "_, idx = tree.query([svd[target]], k=6)\n",
    "\n",
    "[df.title[i] for i in idx[0] if i != target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "## Exercise\n",
    "\n",
    "- Can you visualize the document clusters with t-SNE or UMAP?\n",
    "\n",
    "See the **Unsupervised clustering** notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "geoml",
   "language": "python",
   "name": "geoml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
