{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seismic well tie\n",
    "\n",
    "Let's make a synthetic with open source software! (And data!!)\n",
    "\n",
    "This notebook uses `bruges`, `welly` (which uses `lasio`) and `segyio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load well logs: `welly` and `lasio`\n",
    "\n",
    "We'll use `welly` to faciliate loading curves from an LAS file. Welly uses `lasio` to do the actual file reading.\n",
    "\n",
    "Welly's `project` lets us load lots of wells. You can think of it like a list of wells with a few superpowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from welly import Well, Project\n",
    "\n",
    "base = \"https://geocomp.s3.amazonaws.com/data/{}.las\"\n",
    "\n",
    "urls = [base.format(w) for w in ['R-39', 'L-30', 'R-90']]\n",
    "\n",
    "wells = [Well.from_las(url) for url in urls]\n",
    "\n",
    "p = Project(wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "for w in p:\n",
    "    w.header.uwi = w.header.name\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a well and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Read one single well:\n",
    "#    from welly import Well\n",
    "#    l30 = Well.from_las('../data/L-30.las')\n",
    "\n",
    "# But we have already loaded the well in the project.\n",
    "# We can use its index...\n",
    "#    l30 = p[2]\n",
    "# ...or its UWI to get at it.\n",
    "l30 = p.get_well('PENOBSCOT L-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from welly import Well\n",
    "\n",
    "l30 = Well.from_las('../data/L-30.las')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l30.data[\"DT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l30.data[\"RHOB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2)\n",
    "l30.data[\"RHOB\"].plot(ax=ax0)\n",
    "l30.data[\"DT\"].plot(ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "dt = l30.data[\"DT\"].top_and_tail()\n",
    "rhob = l30.data[\"RHOB\"].to_basis_like(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "dt.units, dt.mnemonic, dt.start, dt.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "rhob.units, rhob.mnemonic, rhob.start, rhob.stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "- The density log is in g/cm³ — convert it to kg/m³.\n",
    "- Retrieve the DT (slowness) log and convert it to μs/m.\n",
    "- Compute a P-wave velocity (Vp) log in m/s from the slowness log.\n",
    "- Compute the product of Vp and density to yield impedance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "dt /= 0.3048\n",
    "dt.units = 'µs/m'\n",
    "\n",
    "rhob *= 1000\n",
    "rhob.units = 'kg/m3'\n",
    "\n",
    "vp = 1e6 / dt\n",
    "vp.mnemonic = 'VP'\n",
    "vp.units = 'm/s'\n",
    "\n",
    "ai = vp * rhob\n",
    "ai.mnemonic = 'AI'\n",
    "ai.units = 'Pa.s/m'  # Units of acoustic impedance for linear travel. \"Viscosity per unit length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "ai.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 2))\n",
    "plt.plot(ai.basis, ai, lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth to time conversion: `numpy.interp()`\n",
    "\n",
    "The logs are in depth, but the seismic is in travel time. So we need to convert the well data to time.\n",
    "\n",
    "We don't know the seismic time, but we can model it from the DT curve: since DT is 'elapsed time', in microseconds per metre, we can just add up all these time intervals for 'total elapsed time'. Then we can use that to 'look up' the time of a given depth.\n",
    "\n",
    "We use the step size to scale the DT values to 'seconds per step' (instead of µs/m).\n",
    "\n",
    "We will need to know:\n",
    "\n",
    "- The sample interval of the DT log.\n",
    "- The well measurement datum.\n",
    "- The ground level or water depth.\n",
    "- The replacement velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l30.las.header['Well']['GL'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = 0.3048 * l30.las.header['Well']['APDAT'].value  # This log is measured from RT not KB.\n",
    "gl = 0.3048 * l30.las.header['Well']['GL'].value     # NB Before welly v 0.4.8 these were not captured.\n",
    "\n",
    "rt, gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.start  # Relative to RT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "Do the arithmetic to find the timing of the top of the log. You need to know:\n",
    "\n",
    "- Velocity is distance divided by time.\n",
    "- The replacement velocity is unknown, use 1800 m/s for now.\n",
    "- Use 1480 m/s as the velocity of water.\n",
    "- Remember to multiply travel-times by 2 to get TWT.\n",
    "\n",
    "You should get:\n",
    "\n",
    "    Water time: 0.186 s\n",
    "    Repl time:  0.204 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start =         # Start of DT log\n",
    "\n",
    "v_water =       # Velocity of water\n",
    "v_repl =        # Replacement velocity\n",
    "\n",
    "water_layer =   # Depth of water\n",
    "repl_layer =    # Thickness of replacement layer\n",
    "\n",
    "water_twt =     # TWT in water, using water_layer and v_water\n",
    "repl_twt =      # TWT in replacement layer, using repl_layer and v_repl\n",
    "\n",
    "print(f\"Water time: {water_twt:.3f} s\\nRepl time:  {repl_twt:.3f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "start = dt.start\n",
    "\n",
    "v_water = 1480\n",
    "v_repl = 1800\n",
    "\n",
    "water_layer = -gl\n",
    "repl_layer = start - water_layer - rt\n",
    "\n",
    "water_twt = 2 * water_layer / v_water\n",
    "repl_twt = 2 * repl_layer / v_repl\n",
    "\n",
    "print(f\"Water time: {water_twt:.3f} ms\\nRepl time:  {repl_twt:.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to scale the DT log so that the samples represent 'elapsed time per sample':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dt = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "scaled_dt = dt.step * dt * 1e-6  # Convert to seconds per step\n",
    "scaled_dt.units = \"s/sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally we can compute the cumulative time elapsed on the DT log.\n",
    "\n",
    "This is the time-depth table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_time = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "dt_time = water_twt + repl_twt + 2 * np.cumsum(scaled_dt)\n",
    "dt_time.units = \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_time.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then use this to convert the logs to a time basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delt =             # Sample interval.\n",
    "maxt =             # Max time that we need — longer than the log, and a multiple of delt.\n",
    "n_samples =        # How many samples will that be?\n",
    "\n",
    "seis_time = \n",
    "\n",
    "ai_t = np.interp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "delt = 0.004                 # Sample interval.\n",
    "maxt = np.ceil(dt_time[-1])  # Max time that we need; needs to be longer than the log.\n",
    "n_samples = int(maxt / delt) + 1\n",
    "\n",
    "# Make a regular time basis: the seismic time domain.\n",
    "seis_time = np.linspace(0, maxt, n_samples) \n",
    "\n",
    "# OR...\n",
    "# seis_time = np.arange(0, maxt, delt)\n",
    "\n",
    "# Interpolate the AI log onto this basis.\n",
    "ai_t = np.interp(seis_time, dt_time, ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this last step with `scipy`, which I prefer because (a) I prefer the API and (b) we have more options for interpolation algorithms (at least we do when we don't have a lot of NaNs in the data!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "f = interp1d(dt_time, ai, kind=\"slinear\", bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n",
    "ai_t_ = f(seis_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "We'll turn all of this into functions.\n",
    "\n",
    "- Make a time-conversion function to get time-converted logs from `delt`, `maxt`, `dt_time`, and a log.\n",
    "- Make a function to get `dt_time` from `datum`, `gl`, `dt`, `v_water`, `v_repl`.\n",
    "- Recompute `ai_t` by calling your new functions.\n",
    "- Plot the DT log in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dt_time(dt, datum, gl, v_repl, v_water=1480):\n",
    "    \"\"\"\n",
    "    Compute DT time from the dt log and some other variables.\n",
    "    \n",
    "    The DT log must be a welly curve object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Your code here!\n",
    "    \n",
    "    return dt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_dt_time(dt, datum, gl, v_repl, v_water=1480):\n",
    "    \"\"\"\n",
    "    Compute DT time from the dt log and some other variables.\n",
    "    \n",
    "    The DT log must be a welly curve object.\n",
    "    \"\"\"\n",
    "    start = dt.start\n",
    "\n",
    "    water_layer = -gl\n",
    "    repl_layer = start - datum - water_layer\n",
    "    \n",
    "    water_twt = 2 * water_layer / v_water\n",
    "    repl_twt = 2 * repl_layer / v_repl\n",
    "\n",
    "    scaled_dt = dt.step * dt * 1e-6\n",
    "    dt_time = water_twt + repl_twt + 2*np.cumsum(scaled_dt)\n",
    "    dt_time.units = \"s\"\n",
    "\n",
    "    return dt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convert(log, dt_time, delt=0.004, maxt=3.0):\n",
    "    \"\"\"\n",
    "    Converts log to the time domain, given dt_time, delt, and maxt.\n",
    "    \n",
    "    dt_time is elapsed time regularly sampled in depth. log must\n",
    "    be sampled on the same depth basis.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here!\n",
    "    \n",
    "    return log_t, seis_time  # Give the time basis back as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def time_convert(log, dt_time, delt=0.004, maxt=None):\n",
    "    \"\"\"\n",
    "    Converts log to the time domain, given dt_time, delt, and maxt.\n",
    "    \n",
    "    dt_time is elapsed time regularly sampled in depth. log must\n",
    "    be sampled on the same depth basis.\n",
    "    \"\"\"\n",
    "    maxt = maxt or np.ceil(dt_time[-1])\n",
    "    t_seis = np.arange(0, maxt, delt)\n",
    "    return np.interp(t_seis, dt_time, log), t_seis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then these should work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_time = compute_dt_time(dt, rt, gl, v_repl=1800)\n",
    "ai_t, t_seis = time_convert(ai, dt_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute reflectivity\n",
    "\n",
    "Now, at last, we can compute the reflection coefficients in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rc(ai):\n",
    "    \"\"\"\n",
    "    Make reflections from impedance log.\n",
    "    \"\"\"\n",
    "    rc = (ai[1:] - ai[:-1]) / (ai[1:] + ai[:-1])\n",
    "    return np.pad(rc, (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = get_rc(ai_t)\n",
    "rc[np.isnan(rc)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "plt.stem(t_seis[600:700], rc[600:700], use_line_collection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolve with a wavelet: `bruges`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bruges.filters import ricker\n",
    "\n",
    "w, t = ricker(0.128, 0.004, 20, return_t=True, sym=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = np.convolve(rc, w, mode=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,2))\n",
    "plt.plot(t_seis, syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, stop = 220, 350\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(seis_time[start:stop], syn[start:stop], c='g', lw=2)\n",
    "\n",
    "pts, stems, base = plt.stem(seis_time[start:stop], rc[start:stop], use_line_collection=True)\n",
    "plt.setp(pts, markersize=5, c='r')\n",
    "plt.setp(base, lw=0.75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "Make an interactive plot to allow us to vary the frequency of the wavelet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(f=(4, 60, 4))\n",
    "def makeplot(f):\n",
    "    \n",
    "    w, t = ricker(0.128, 0.004, f, return_t=True, sym=True)\n",
    "    syn = np.convolve(rc, w, mode=\"same\")\n",
    "\n",
    "    start, stop = 250, 350\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(seis_time[start:stop], syn[start:stop], c='g', lw=2)\n",
    "\n",
    "    pts, stems, base = plt.stem(seis_time[start:stop], rc[start:stop], use_line_collection=True)\n",
    "    plt.setp(pts, markersize=5, c='r')\n",
    "    plt.setp(base, lw=0.75)\n",
    "    \n",
    "    plt.xlabel('TWT [s]')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the seismic: `segyio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segyio\n",
    "\n",
    "with segyio.open('../data/Penobscot_xl1155.sgy') as s:\n",
    "    seismic = segyio.cube(s)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The synthetic is at trace number 77. We need to make a shifted version of the synthetic to overplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace, gain = 77, 50\n",
    "s = trace + gain*syn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can define semi-real-world cordinates of the seismic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = np.percentile(seismic, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(seismic.T, cmap='Greys', extent=(0, 400, 4.0, 0), aspect='auto', vmin=-ma, vmax=ma)\n",
    "plt.plot(s, t_seis, c='cyan')\n",
    "plt.fill_betweenx(t_seis, trace, s, where=syn>0, lw=0, color='cyan')\n",
    "plt.xlim(0, 400)\n",
    "plt.ylim(3.2, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "If we wanted to stretch the synthetic a little, the easiest thing to do is to create a new version of the DT log that we only use for time-keeping (you don't want time-based edits to be used for reflectivity). Then we can, for example, spread a time-shift at 2.5 s across the whole log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_dt_time(dt, datum, gl, v_repl, v_water=1480, shift=None):\n",
    "    \"\"\"\n",
    "    Compute DT time from the dt log and some other variables.\n",
    "    \n",
    "    The DT log must be a welly curve object.\n",
    "    \"\"\"\n",
    "    start = dt.start\n",
    "\n",
    "    water_layer = -gl\n",
    "    repl_layer = start - datum - water_layer\n",
    "    \n",
    "    water_twt = 2 * water_layer / v_water\n",
    "    repl_twt = 2 * repl_layer / v_repl\n",
    "\n",
    "    if shift is not None:\n",
    "        dt_corr = 1e6 * shift / dt.size \n",
    "    else:\n",
    "        dt_corr = 0\n",
    "\n",
    "    scaled_dt = dt.step * dt * 1e-6\n",
    "    scaled_dt_corr = dt.step * (dt+dt_corr) * 1e-6\n",
    "    dt_time = water_twt + repl_twt + 2 * np.cumsum(scaled_dt)\n",
    "    dt_corr_time = water_twt + repl_twt + 2 * np.cumsum(scaled_dt_corr)\n",
    "    dt_time.units = \"s\"\n",
    "\n",
    "    return dt_time, dt_corr_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "shift = 0.2   # seconds\n",
    "\n",
    "dt_time, dt_corr = compute_dt_time(dt, rt, gl, v_repl=1800, shift=shift)\n",
    "ai_t, t_seis = time_convert(ai, dt_corr)\n",
    "dt_t, _ = time_convert(dt, dt_corr)\n",
    "rho_t, _ = time_convert(rhob, dt_corr)\n",
    "\n",
    "rc = get_rc(ai_t)\n",
    "rc[np.isnan(rc)] = 0\n",
    "syn = np.convolve(rc, w, mode=\"same\")\n",
    "s = trace + gain*syn\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(seismic.T, cmap='Greys', extent=(0, 400, 4.0, 0), aspect='auto', vmin=-ma, vmax=ma)\n",
    "plt.plot(s, t_seis, c='cyan')\n",
    "# plt.plot(trace + rho_t*dt_t*0.00005, t_seis, c='green')\n",
    "plt.fill_betweenx(t_seis, trace, s, where=syn>0, lw=0, color='cyan')\n",
    "plt.xlim(0, 400)\n",
    "plt.ylim(3.2, 0)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(dt_time)\n",
    "plt.plot(dt_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "zz[-1] - dt_time[-1]\n",
    "\n",
    "# This should be the time shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model a DTS log: `scikit` for now\n",
    "\n",
    "We'd like to compute a gather, but this well doesn't have a shear sonic. Let's use another well to build a linear model from P-wave sonic and density.\n",
    "\n",
    "First, we'll read data from another well and make our `X` matrix and and `y` vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r39 = p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = r39.data['DT4S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DTS has some problems (try plotting it!), so we'll fix those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts[dts < 0] = np.nan\n",
    "r39.data['DT4S'] = dts.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r39.data_as_matrix(keys=['RHOB', 'DT4P', 'DT4S'])\n",
    "X = data[:, :2]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*data[:, :2].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can select and fit a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "regr = Ridge().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an `X` for application..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l30.data['DT'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_appl = l30.data_as_matrix(keys=['RHOB', 'DT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and apply the model to make a prediction for DTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = regr.predict(np.nan_to_num(X_appl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we think of this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll have to go back and fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn this into a curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from welly import Curve\n",
    "\n",
    "dts = Curve(dts, basis=l30.data['DT'].basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix some problems with bad (probably casing) values at the top and bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts[dts < 100] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backus averaging\n",
    "\n",
    "Computing acoustic impedance this way is fine for a first pass, but eventually you'll want it to be more accurate. There's a couple of issues:\n",
    "\n",
    "- It doesn't account for the limited seismic bandwidth.\n",
    "- It doesn't account for anisotropy.\n",
    "- It doesn't account for offset.\n",
    "\n",
    "So let's employ Backus averaging, which gets at the first 2 points. According to Sherriff:\n",
    "\n",
    "> An effective-medium theory used to upscale sonic-log data for synthetic seismogram manufacture. Involves harmonic averaging to find the anisotropic elastic parameters that characterize seismic-wave propagation at low frequencies in a layered medium.\n",
    "\n",
    "Mavko suggests 10&times; the layer thickness (or beds in the formation) for the averaging length. So let's start with 10 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bruges as bg\n",
    "\n",
    "vs = 1e6 / dts\n",
    "vs.mnemonic = 'VS'\n",
    "vs.units = 'm/s'\n",
    "\n",
    "vp0, vs0, rho0 = bg.rockphysics.backus(vp, vs, rhob, lb=10, dz=0.1524)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp0.shape, vp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vp)\n",
    "plt.plot(vp0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute offset gather\n",
    "\n",
    "Now we can time-convert all the logs (before we just did the acoustic impedance log) and compute reflectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_t, _ = time_convert(vp0, dt_time)\n",
    "vs_t, _ = time_convert(vs0, dt_time)\n",
    "rhob_t, _ = time_convert(rho0, dt_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "Use `bruges.reflection.reflectivity()`, which takes the logs we just made, to compute the offset-dependent reflectivity for, say, incident angles from 0 to 45 degrees.\n",
    "\n",
    "You should end up with an `rc` array of shape (46, 749). Plot this array with `plt.imshow()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "import bruges\n",
    "\n",
    "rc = bruges.reflection.reflectivity(vp_t, vs_t, rhob_t, theta=np.linspace(0, 40, 41))\n",
    "\n",
    "rc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "rc_ = rc.T.real\n",
    "\n",
    "plt.figure(figsize=(6, 15))\n",
    "plt.imshow(rc_[250:500], aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the intercept and gradient for this dataset...\n",
    "I, G = bruges.reflection.shuey(vp_t[:-1], vs_t[:-1], rhob_t[:-1],\n",
    "                               vp_t[1:], vs_t[1:], rhob_t[1:],\n",
    "                               theta1=np.arange(0, 40, 1),\n",
    "                               return_gradient=True\n",
    "                              )\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(I, G, c=t_seis[:-1])\n",
    "plt.axhline(0, c='k')\n",
    "plt.axvline(0, c='k')\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# To compute intercept and gradient from a real gather, we could do this...\n",
    "I = (rc_[:, -1] - rc_[:, 0]) / np.sin(np.radians(40))**2\n",
    "G = rc_[:, 0]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(I, G, c=np.arange(rc_.shape[0]))\n",
    "plt.axhline(0, c='k')\n",
    "plt.axvline(0, c='k')\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "Make a Ricker wavelet then use `np.apply_along_axis()` to make a 2D synthetic.\n",
    "\n",
    "Finally, plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = bruges.filters.ricker(0.256, 0.002, 20, sym=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "w = bruges.filters.ormsby(0.256, 0.002, (6, 12, 60, 80), sym=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "syn = np.apply_along_axis(np.convolve, axis=1, arr=rc, v=w, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 10))\n",
    "plt.imshow(syn.real.T, aspect='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### EXERCISE\n",
    "\n",
    "How does the zero-offset (aka normal incidence) synthetic compare to a simulation of the full stack (e.g. 0 to 30 degrees)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "s = syn.real\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(s[0])\n",
    "\n",
    "fullstack = np.sum(s[:30], axis=0) / 30\n",
    "plt.plot(fullstack)\n",
    "\n",
    "plt.grid(c='k', alpha=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other things to try\n",
    "\n",
    "- What difference does Backus averaging, or the improved wavelet, make to the tie quality?\n",
    "- Can you export the synthetic or the gather as a LAS file (using `welly` or `lasio`), or as SEG-Y (using `segyio`)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "<div>\n",
    "<img src=\"https://avatars1.githubusercontent.com/u/1692321?s=50\"><p style=\"text-align:center\">© Agile Geoscience 2020</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
