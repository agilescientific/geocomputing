{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6329aa49",
   "metadata": {},
   "source": [
    "# Introduction to IO (Input/Output)\n",
    "\n",
    "We inevitably will need to read data from various places and formats in order to do things with them. This notebook is an overview of some common formats and common ways to read and/or write them. This is absolutely not an exhaustive list of what can be read in python, so if you have specific requests, please do reach out.\n",
    "\n",
    "The following will not import everything upfront. We will start with some generic formats, and then some more specialised subsurface/geoscience formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b405c43",
   "metadata": {},
   "source": [
    "## CSV or TSV files\n",
    "\n",
    "A very common format, which is plain text with some sort of delimiter character (often `,` or `;`) separating each column, and newlines separating records. There are a number of ways to load these, depending on the intended use-case. Numpy or Pandas are probably the most common. D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb8e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.genfromtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a3f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c1016",
   "metadata": {},
   "source": [
    "## Excel Files\n",
    "\n",
    "The easiest for this is definitely pandas. You will need to install `xlrd` as well, since this is an optional library used in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff0d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b5c73",
   "metadata": {},
   "source": [
    "It is worth noting that you can either read individual worksheets, or load multiple ones into one dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f546eda",
   "metadata": {},
   "source": [
    "## Databases\n",
    "\n",
    "There are numerous ways of reading a database, which partially depends on the type of database. Pandas can read or write SQL, so it a reasonable starting point.\n",
    "\n",
    "For a more powerful and flexible option, consider [sqlalchemy](https://www.sqlalchemy.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae771153",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "JavaScript Object Notation is a very common format used to exchange information on the internet, so you may get this back from various Application Programming Interfaces (APIs). It is very similar to a python `dict`, which is how these are usually handled once they are loaded. There is a built-in library for working with these, logically enough named `json`. This can handle json files in string format as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6ce305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76145e0",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "The following are more geoscience or subsurface data formats.\n",
    "\n",
    "## Shapefiles\n",
    "\n",
    "These are a common geographical information system format, originally developed by Esri. A simple way to load these is to use geopandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa2e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e29ef",
   "metadata": {},
   "source": [
    "Because geopandas uses `fiona` in the background for file handling, it can handle the following formats in addition to shapefiles. Files with `'r'` can read from, `'w'` can be written to, and `'a'` can be appended to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a3ec316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ARCGEN': 'r',\n",
       " 'DXF': 'rw',\n",
       " 'CSV': 'raw',\n",
       " 'OpenFileGDB': 'r',\n",
       " 'ESRIJSON': 'r',\n",
       " 'ESRI Shapefile': 'raw',\n",
       " 'FlatGeobuf': 'rw',\n",
       " 'GeoJSON': 'raw',\n",
       " 'GeoJSONSeq': 'rw',\n",
       " 'GPKG': 'raw',\n",
       " 'GML': 'rw',\n",
       " 'OGR_GMT': 'rw',\n",
       " 'GPX': 'rw',\n",
       " 'GPSTrackMaker': 'rw',\n",
       " 'Idrisi': 'r',\n",
       " 'MapInfo File': 'raw',\n",
       " 'DGN': 'raw',\n",
       " 'PCIDSK': 'rw',\n",
       " 'OGR_PDS': 'r',\n",
       " 'S57': 'r',\n",
       " 'SQLite': 'raw',\n",
       " 'TopoJSON': 'r'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fiona\n",
    "fiona.supported_drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb576c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.geodataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e95b0",
   "metadata": {},
   "source": [
    "## LAS files\n",
    "\n",
    "`lasio` is a library that is able to read LAS2 files, but `welly` is a wrapper that may be nicer to use for everyday use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3444dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from welly import Well, Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c10502",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Well.from_las()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae257a7",
   "metadata": {},
   "source": [
    "Welly can also load an entire directory of las files into a `Project`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486fcea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Project.from_las()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aaf35f",
   "metadata": {},
   "source": [
    "## SEG-Y\n",
    "\n",
    "The SEG-Y format is widely-used, although any given individual file can be tricky to load. Equinor has written a low-level library named [`segyio`](https://github.com/equinor/segyio) which can (with some effort in some cases) read and write SEG-Y files and headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9930266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segyio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with segyio.open() as s:\n",
    "    vol = s.cube()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d2123",
   "metadata": {},
   "source": [
    "Given that `segyio` is intended for relatively low-level operations, it means that there is a fair amount of work to get things working. An alternative, built on top of it is SEGY Swis Army Knife ([SEGYSAK](https://segysak.readthedocs.io/en/latest/index.html)). This is intended to make common operations a little easier. It also interfaces with `xarray`, which is an extension of numpy, and well-worth a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segysak.segy import segy_loaderder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87dc040",
   "metadata": {},
   "outputs": [],
   "source": [
    "segy_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e63630",
   "metadata": {},
   "source": [
    "## DLIS files\n",
    "\n",
    "Equinor have written a library named `dlisio` that can handle dlis files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbeb109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlisio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to confirm how this one works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f8ebed",
   "metadata": {},
   "source": [
    "## Other Assorted Formats\n",
    "\n",
    "The subsurface world is filled with all sorts of other formats. Agile Scientific has written a library named `gio` that can handle a variety of these, such as OpendTect horizons, Surfer 7 grids, and ZMaps. These are loaded as `xarray`s. The documentation has [more details](https://code.agilescientific.com/gio/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677151a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gio.read_odt(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocomp",
   "language": "python",
   "name": "geocomp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
